<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Quan Mai</title>
        <link rel="stylesheet" href="../css/bulma.css">
        <link rel="stylesheet" href="../css/mine.css">
        <link href="https://cdn.jsdelivr.net/npm/@coreui/icons/css/all.min.css" rel="stylesheet">
        <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
        <script
            src="https://code.jquery.com/jquery-3.3.1.js"
            integrity="sha256-2Kok7MbOyxpgUVvAk/HJ2jigOSYS2auK4Pfzbm7uH60="
            crossorigin="anonymous">
        </script>

        <div id="navbar"></div>
        <!-- <div id="footer"></div> -->
        <script>
            $(function() {
                $("#footer").load("../footer.html");
                $("#about").load("../about.html");
                $("#navbar").load("../navbar.html");
            });
        </script>

        <!-- <style>
            body {
                counter-reset: section;
            }
            h2 {
                counter-reset: subsection;
            }
            h2::before {
                counter-increment: section;
                content: counter(section) ". ";
                font-weight: bold;
            }
            h3::before {
                counter-increment: subsection;
                content: counter(section) "." counter(subsection) " ";
                font-weight: bold;
            }
        </style> -->

    </head>

    <body>
        <div class="columns">
            <div class="column is-2">
                <aside class="menu">
                    <p class="menu-label">But why</p>
                        <ul class="menu-list">
                            <li><a href="../learning.html">Because...</a></li>
                        </ul>
                    <p class="menu-label">Writings</p>
                        <ul class="menu-list">
                            <li><a href="diffusion.html">Diffusion Models</a></li>
                            <li><a class="is-active" href="">Diffusion as a Manifold Sculptor</a></li>
                            <li><a href="transformer.html">Transformers</a></li>
                            <li><a href="adaptive_memory.html">Adaptive Memory Retrieval in LLM Agents</a></li>
                        </ul>
                    <p class="menu-label">Paper Summary</p>
                    <ul class="menu-list">
                        <li><a href="memgpt.html">MemGPT</a></li>
                    </ul>
                </aside>

            </div>
            
            <div class="column is-6 is-offset-1">
                <section class="section">
                    <div class="container">
                        <div class="content is-size-5">
                            <h1 class="title is-1 has-text-weight-bold has-text-centered is-family-sans-serif">Diffusion as a Manifold Sculptor</h1>
                            <p class="has-text-centered">
                                Quan Mai
                            </p>
                            <br>
                            <p>
                                In math and machine learning, a <a href="https://en.wikipedia.org/wiki/Manifold">Manifold</a> is a lower-dimensional, smooth surface
                                embedded in a higher-dimensional space. For embeddings, the idea is that the data points
                                (documents, images, etc.) lie on some intrinsic structure - a curve <q>sheet</q> defined by
                                the underlying relationships in the data - rather than filling the full higher-dimensional space randomly.
                                <br><br>
                                <b>Pretrained Embeddings as a Manifold:</b> When a model like BERT<a href="#ref-1" id="citation1"><sup>[1]</sup></a> spits out embeddings, they are not
                                just random points in 768-D space. The training process (e.g., masked language modeling) contrains them
                                to a subspace reflecting linguistic patterns - similar sentences cluster, dissimilar ones drift apart.
                                <br>
                                While it's a manifold, it's not necessarily optimized for a specific
                                task (e.g., document retrieval, QA). BERT's manifold is tuned for general language understanding - good
                                for many things, but not perfert for fine-grained tasks. It's a <i>general-purpose manifold,</i> not
                                a task-specific one.
                            </p>

                            <br>
                            <h2>Diffusion Models: Shapping the Manifold</h2>
                            <p>
                                <b>Diffusion Models</b><a href="#ref-2" id="citation2"><sup>[2]</sup></a> are popular in generative tasks such as image synthesis (e.g., DALL-E, Stable Diffusion),
                                they work by iteratively refining noisy data back to a clean, high-quality state. Here, instead of creating 
                                a manifold from a scratch, diffusion models will <i>refine and reshape</i> the existing one 
                                to better suit the task at hand. Let us take the retrieval task as the example here. 
                                <br><br>
                                Given a query, we want to find the most relevant documents in the corpus. At the starting point, we 
                                use the pretrained embeddings (e.g., BERT) to represent the query and documents. The raw BERT embeddings are on 
                                a pretrained manifold, it's decent (semantically meaningful) but might not align perfertly 
                                with retrieval goals. Here's where the diffusion model comes in...
                                <br><br>

                                By adding noise and iteratively denoising, the diffusion model perturbs these embeddings and learns
                                to restore them in a way that emphasizes the task-specific structure. The noise here is important:
                                <ul class="is-size-5">
                                    <li> 
                                        <b>Noise as Explorer:</b> Adding Gaussion noise <q>shake</q> the embeddings off the original manifold,
                                        exploring nearby regions in the high-dimensional space.
                                    </li>
                                    <li>
                                        <b>Denoising as Sculptor:</b> The model, trained to reverse the noise (e.g., via MSE or contrastive learning), pulls the embedding back,
                                        not to their exact original spots, but to a new location that better aligns with the retrieval task.
                                    </li>
                                </ul>
                            </p>
                            
                            <p>

                                The refined embeddings still from a manifold - a continuous, lower-dimensional structure - but it's 
                                now <b>task-tailored.</b>
                            </p>
                                
                            <!-- <div class="columns is-vcentered">
                                <div class="column is-three-quarters">
                                    <p class="content">
                                        Denoising diffusion models, at an abstract level, are about gradually transforming data through structured randomness. 
                                        They leverage a forward and reverse process to denoise corrupted data step by step, revealing a meaningful structure. 
                                        This process can be thought of as sculpting a statue from a block of marble.
                                    </p>
                                </div>
                            
                                <div class="column is-one-quarter">
                                    <figure class="image is-4by3">
                                        <img src="../assets/clay.jpg" alt="Diffusion Model Illustration">
                                    </figure>
                                </div>
                            </div> -->


                            <div class="has-text-centered">
                                <figure class="image is-inline-block">
                                    <img src="../assets/clay.jpg">
                                    <p>Sculpting clay (Photo: <a rel="Website" href="https://acrylgiessen.com" target="_blank">acrylgiessen.com</a>) </p>
                                </figure>
                            </div>     
                            <br><br>
                            <blockquote class="is-size-5">
                                We can think of pretrained embeddings as a rough clay sculpture. It already has a shape (a manifold) but not detailed for our needs.
                                The diffusion model is like an artist, it smudges the clay (add noise) and then smooths it out (denoising), refining the contours
                                to highlight the features we care about. The clay is still there - it's not a new sculpture - just better molded.
                            </blockquote>  
                            <br>

                            <h2>Refinement, not Replacement</h2>
                            <p>
                                The key here is that diffusion model does not discard BERT's manifold, it does leverage it as a strong
                                foundation. Diffusion here acts as a fine-tuner, using a pretrained manifold as a head start (better than a random
                                vectors). Without that starting structure, denoising from pure noise would be much harder and less effective.
                            </p>
                            <br>

                            <h2>So, Yes - Diffusion Model Can Be a Manifold Sculptor</h2>
                            <p>
                                The diffusion model's job here is to <b>shape the existing manifold</b>. It takes the pretrained embeddings'
                                inherent structure and molds it into a form  that's more useful for retrieval. It's neither a discriminator
                                nor a generator - it's a <b>manifold sculptor</b>, enhancing what's already there.
                            </p>
                            <br>
                            
                            <h2>Of Course, No Free Lunch!</h2>
                            <p>
                                While the idea sounds promising (ikr), and diffusion models are powerful, they are not a silver bullet. 
                                
                                <br><br>
                                <b>Computational Cost: </b>Remember that the reverse process (denoising) is iteratively, which means it's not a one-shot operation.
                                We have to denoise the embeddings multiple times (say, 100) to get the refined version.
                                Of course we can pre-refine the documents and store them in a database, as in the case of dense retrieval.
                                Running 100 denoising steps per document, for a corpus of millions of documents, can be computationally expensive.
                                <br><br>
                                <b>Training Complexity:</b> We need a smart loss function to guide the denoising toward <q>discrimitive</q> rather
                                than just <q>clean</q>. Contrasitve loss might work, but I am not certain. If I have a paper on this topic, I will
                                let you know 😊.
                            </p>


                            <br><br>
                            <h2>References</h2>
                            <ol class="reference-list">
                                <li id="ref-1">
                                    Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova,
                                    "<i>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</i>,"
                                    arXiv preprint arXiv:1810.04805, 2018. 
                                    <a href="https://arxiv.org/abs/1810.04805" target="_blank">[arXiv:1810.04805]</a>
                                    <a href="#citation1">↑ Back to text</a>
                                </li>
                                
                                <li id="ref-2">
                                    Jonathan Ho, Ajay Jain, Pieter Abbeel, 
                                    "<i>Denoising Diffusion Probabilistic Models</i>," 
                                    Advances in Neural Information Processing Systems (NeurIPS), 2020.  
                                    <a href="https://arxiv.org/abs/2006.11239" target="_blank">[arXiv:2006.11239]</a>  
                                    <a href="#citation2">↑ Back to text</a>
                                </li>

                            </ol>


                        </div>
                    </div>    
                </section>
            </div>
    </body>
</html>